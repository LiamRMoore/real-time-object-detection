{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a9206f",
   "metadata": {},
   "source": [
    "# Try PP-Picodet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8751bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0,\"..\")\n",
    "\n",
    "import torch\n",
    "import mmdet\n",
    "import mmcv\n",
    "import pandas as pd\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.models import build_detector\n",
    "from mmcv import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6827b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.detectors.picodet import PicoDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "762c833b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'backbone', 'neck', and 'bbox_head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mPicoDet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'backbone', 'neck', and 'bbox_head'"
     ]
    }
   ],
   "source": [
    "m = PicoDet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4427a83a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'channel_shuffle' from 'mmdet.models.utils' (/root/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/mmdet/models/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmdet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m channel_shuffle\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'channel_shuffle' from 'mmdet.models.utils' (/root/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/mmdet/models/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from mmdet.models.utils import channel_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c27130",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ModuleNotFoundError: No module named 'mmdet.models.detectors.picodet'\"\"\"\n",
    "\"\"\"ModuleNotFoundError: No module named 'mmdet.models.backbones.esnet'\"\"\"\n",
    "\"\"\"ImportError: cannot import name 'EnhancedInvertedResidual' from 'mmdet.models.utils' (/root/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/mmdet/models/utils/__init__.py)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1af066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "root@d0eb2391c6e5:/usr/app# vim /root/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/mmdet/models/utils/__init__.py\n",
    "root@d0eb2391c6e5:/usr/app# vim /root/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/mmdet/models/utils/inverted_residual.py \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d23b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ModuleNotFoundError: No module named 'mmdet.models.necks.csp_pan'\"\"\"\n",
    "\"\"\"ModuleNotFoundError: No module named 'mmdet.models.dense_heads.picodet_head'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6225cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60d2233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(config_file)\n",
    "\n",
    "# set cudnn_benchmark\n",
    "if cfg.get('cudnn_benchmark', False):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "cfg.model.pretrained = None\n",
    "if cfg.model.get('neck'):\n",
    "    if isinstance(cfg.model.neck, list):\n",
    "        for neck_cfg in cfg.model.neck:\n",
    "            if neck_cfg.get('rfp_backbone'):\n",
    "                if neck_cfg.rfp_backbone.get('pretrained'):\n",
    "                    neck_cfg.rfp_backbone.pretrained = None\n",
    "    elif cfg.model.neck.get('rfp_backbone'):\n",
    "        if cfg.model.neck.rfp_backbone.get('pretrained'):\n",
    "            cfg.model.neck.rfp_backbone.pretrained = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76333322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'PicoDet',\n",
       " 'backbone': {'type': 'ESNet',\n",
       "  'model_size': 's',\n",
       "  'out_indices': [2, 9, 12],\n",
       "  'frozen_stages': -1,\n",
       "  'norm_cfg': {'type': 'BN', 'requires_grad': True},\n",
       "  'norm_eval': False,\n",
       "  'act_cfg': {'type': 'HSwish'},\n",
       "  'se_cfg': {'conv_cfg': None,\n",
       "   'ratio': 4,\n",
       "   'act_cfg': ({'type': 'ReLU'},\n",
       "    {'type': 'HSigmoid', 'bias': 3.0, 'divisor': 6.0, 'max_value': 6.0})},\n",
       "  'init_cfg': {'type': 'Pretrained',\n",
       "   'checkpoint': 'MODEL_DIR/ESNet_x0_75_pretrained_mmdet_format.pth'}},\n",
       " 'neck': {'type': 'CSPPAN',\n",
       "  'in_channels': [96, 192, 384],\n",
       "  'act_cfg': {'type': 'HSwish'},\n",
       "  'norm_cfg': {'type': 'BN', 'requires_grad': True},\n",
       "  'out_channels': 96,\n",
       "  'num_features': 4,\n",
       "  'expansion': 1,\n",
       "  'num_csp_blocks': 1},\n",
       " 'bbox_head': {'type': 'PicoDetHead',\n",
       "  'num_classes': 80,\n",
       "  'in_channels': 96,\n",
       "  'feat_channels': 96,\n",
       "  'stacked_convs': 2,\n",
       "  'kernel_size': 5,\n",
       "  'share_cls_reg': True,\n",
       "  'use_depthwise': True,\n",
       "  'reg_max': 7,\n",
       "  'act_cfg': {'type': 'HSwish'},\n",
       "  'strides': [8, 16, 32, 64],\n",
       "  'norm_cfg': {'type': 'BN', 'requires_grad': True},\n",
       "  'use_vfl': True,\n",
       "  'loss_cls': {'type': 'VarifocalLoss',\n",
       "   'use_sigmoid': True,\n",
       "   'alpha': 0.75,\n",
       "   'gamma': 2.0,\n",
       "   'iou_weighted': True,\n",
       "   'loss_weight': 1.0},\n",
       "  'loss_dfl': {'type': 'DistributionFocalLoss', 'loss_weight': 0.25},\n",
       "  'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 2.0}},\n",
       " 'train_cfg': None,\n",
       " 'test_cfg': {'nms_pre': 1000,\n",
       "  'min_bbox_size': 0,\n",
       "  'score_thr': 0.025,\n",
       "  'nms': {'type': 'nms', 'iou_threshold': 0.6},\n",
       "  'max_per_img': 100},\n",
       " 'pretrained': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f724aab0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PicoDet is not in the models registry'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# build the model and load checkpoint\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_cfg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/mmdet/models/builder.py:58\u001b[0m, in \u001b[0;36mbuild_detector\u001b[0;34m(cfg, train_cfg, test_cfg)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_cfg\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m train_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \\\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_cfg specified in both outer field and model field \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_cfg\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m test_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \\\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_cfg specified in both outer field and model field \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDETECTORS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_cfg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/mmcv/utils/registry.py:234\u001b[0m, in \u001b[0;36mRegistry.build\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/mmcv/cnn/builder.py:27\u001b[0m, in \u001b[0;36mbuild_model_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Sequential(\u001b[38;5;241m*\u001b[39mmodules)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_from_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/mmcv/utils/registry.py:58\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     56\u001b[0m     obj_cls \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mget(obj_type)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m     59\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not in the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregistry\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m registry\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(obj_type) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj_type):\n\u001b[1;32m     61\u001b[0m     obj_cls \u001b[38;5;241m=\u001b[39m obj_type\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PicoDet is not in the models registry'"
     ]
    }
   ],
   "source": [
    "# build the model and load checkpoint\n",
    "cfg.model.train_cfg = None\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07345df8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConfigDict' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/torch/serialization.py:309\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(f\u001b[38;5;241m.\u001b[39mtell())\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/mmcv/utils/config.py:50\u001b[0m, in \u001b[0;36mConfigDict.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConfigDict' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Model class must be defined somewhere\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/torch/serialization.py:236\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _open_buffer_writer(name_or_buffer)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_buffer_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in mode but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/torch/serialization.py:221\u001b[0m, in \u001b[0;36m_open_buffer_reader.__init__\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer):\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_buffer_reader, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(buffer)\n\u001b[0;32m--> 221\u001b[0m     \u001b[43m_check_seekable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/torch/serialization.py:312\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (io\u001b[38;5;241m.\u001b[39mUnsupportedOperation, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 312\u001b[0m     \u001b[43mraise_err_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseek\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/torch/serialization.py:305\u001b[0m, in \u001b[0;36m_check_seekable.<locals>.raise_err_msg\u001b[0;34m(patterns, e)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[1;32m    302\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. You can only torch.load from a file that is seekable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please pre-load the data into a buffer like io.BytesIO and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m try to load from it instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 305\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConfigDict' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead."
     ]
    }
   ],
   "source": [
    "# Model class must be defined somewhere\n",
    "model = torch.load(cfg.model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eafc0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='MMDet test (and eval) a model')\n",
    "    parser.add_argument('config', help='test config file path')\n",
    "    parser.add_argument('checkpoint', help='checkpoint file')\n",
    "    parser.add_argument(\n",
    "        '--work-dir',\n",
    "        help='the directory to save the file containing evaluation metrics')\n",
    "    parser.add_argument('--out', help='output result file in pickle format')\n",
    "    parser.add_argument(\n",
    "        '--fuse-conv-bn',\n",
    "        action='store_true',\n",
    "        help='Whether to fuse conv and bn, this will slightly increase'\n",
    "        'the inference speed')\n",
    "    parser.add_argument(\n",
    "        '--format-only',\n",
    "        action='store_true',\n",
    "        help='Format the output results without perform evaluation. It is'\n",
    "        'useful when you want to format the result to a specific format and '\n",
    "        'submit it to the test server')\n",
    "    parser.add_argument(\n",
    "        '--eval',\n",
    "        type=str,\n",
    "        nargs='+',\n",
    "        help='evaluation metrics, which depends on the dataset, e.g., \"bbox\",'\n",
    "        ' \"segm\", \"proposal\" for COCO, and \"mAP\", \"recall\" for PASCAL VOC')\n",
    "    parser.add_argument('--show', action='store_true', help='show results')\n",
    "    parser.add_argument(\n",
    "        '--show-dir', help='directory where painted images will be saved')\n",
    "    parser.add_argument(\n",
    "        '--show-score-thr',\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help='score threshold (default: 0.3)')\n",
    "    parser.add_argument(\n",
    "        '--gpu-collect',\n",
    "        action='store_true',\n",
    "        help='whether to use gpu to collect results.')\n",
    "    parser.add_argument(\n",
    "        '--tmpdir',\n",
    "        help='tmp directory used for collecting results from multiple '\n",
    "        'workers, available when gpu-collect is not specified')\n",
    "    parser.add_argument(\n",
    "        '--cfg-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file. If the value to '\n",
    "        'be overwritten is a list, it should be like key=\"[a,b]\" or key=a,b '\n",
    "        'It also allows nested list/tuple values, e.g. key=\"[(a,b),(c,d)]\" '\n",
    "        'Note that the quotation marks are necessary and that no white space '\n",
    "        'is allowed.')\n",
    "    parser.add_argument(\n",
    "        '--options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='custom options for evaluation, the key-value pair in xxx=yyy '\n",
    "        'format will be kwargs for dataset.evaluate() function (deprecate), '\n",
    "        'change to --eval-options instead.')\n",
    "    parser.add_argument(\n",
    "        '--eval-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='custom options for evaluation, the key-value pair in xxx=yyy '\n",
    "        'format will be kwargs for dataset.evaluate() function')\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "    if args.options and args.eval_options:\n",
    "        raise ValueError(\n",
    "            '--options and --eval-options cannot be both '\n",
    "            'specified, --options is deprecated in favor of --eval-options')\n",
    "    if args.options:\n",
    "        warnings.warn('--options is deprecated in favor of --eval-options')\n",
    "        args.eval_options = args.options\n",
    "    return args\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "\n",
    "    assert args.out or args.eval or args.format_only or args.show \\\n",
    "        or args.show_dir, \\\n",
    "        ('Please specify at least one operation (save/eval/format/show the '\n",
    "         'results / save the results) with the argument \"--out\", \"--eval\"'\n",
    "         ', \"--format-only\", \"--show\" or \"--show-dir\"')\n",
    "\n",
    "    if args.eval and args.format_only:\n",
    "        raise ValueError('--eval and --format_only cannot be both specified')\n",
    "\n",
    "    if args.out is not None and not args.out.endswith(('.pkl', '.pickle')):\n",
    "        raise ValueError('The output file must be a pkl file.')\n",
    "\n",
    "    cfg = Config.fromfile(args.config)\n",
    "    if args.cfg_options is not None:\n",
    "        cfg.merge_from_dict(args.cfg_options)\n",
    "    # set cudnn_benchmark\n",
    "    if cfg.get('cudnn_benchmark', False):\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    cfg.model.pretrained = None\n",
    "    if cfg.model.get('neck'):\n",
    "        if isinstance(cfg.model.neck, list):\n",
    "            for neck_cfg in cfg.model.neck:\n",
    "                if neck_cfg.get('rfp_backbone'):\n",
    "                    if neck_cfg.rfp_backbone.get('pretrained'):\n",
    "                        neck_cfg.rfp_backbone.pretrained = None\n",
    "        elif cfg.model.neck.get('rfp_backbone'):\n",
    "            if cfg.model.neck.rfp_backbone.get('pretrained'):\n",
    "                cfg.model.neck.rfp_backbone.pretrained = None\n",
    "\n",
    "    # in case the test dataset is concatenated\n",
    "    samples_per_gpu = 1\n",
    "    if isinstance(cfg.data.test, dict):\n",
    "        cfg.data.test.test_mode = True\n",
    "        samples_per_gpu = cfg.data.test.pop('samples_per_gpu', 1)\n",
    "        if samples_per_gpu > 1:\n",
    "            # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
    "            cfg.data.test.pipeline = replace_ImageToTensor(\n",
    "                cfg.data.test.pipeline)\n",
    "    elif isinstance(cfg.data.test, list):\n",
    "        for ds_cfg in cfg.data.test:\n",
    "            ds_cfg.test_mode = True\n",
    "        samples_per_gpu = max(\n",
    "            [ds_cfg.pop('samples_per_gpu', 1) for ds_cfg in cfg.data.test])\n",
    "        if samples_per_gpu > 1:\n",
    "            for ds_cfg in cfg.data.test:\n",
    "                ds_cfg.pipeline = replace_ImageToTensor(ds_cfg.pipeline)\n",
    "\n",
    "    # init distributed env first, since logger depends on the dist info.\n",
    "    if args.launcher == 'none':\n",
    "        distributed = False\n",
    "    else:\n",
    "        distributed = True\n",
    "        init_dist(args.launcher, **cfg.dist_params)\n",
    "\n",
    "    rank, _ = get_dist_info()\n",
    "    # allows not to create\n",
    "    if args.work_dir is not None and rank == 0:\n",
    "        mmcv.mkdir_or_exist(osp.abspath(args.work_dir))\n",
    "        timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "        json_file = osp.join(args.work_dir, f'eval_{timestamp}.json')\n",
    "\n",
    "    # build the dataloader\n",
    "    dataset = build_dataset(cfg.data.test)\n",
    "    data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=samples_per_gpu,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=distributed,\n",
    "        shuffle=False)\n",
    "\n",
    "    # build the model and load checkpoint\n",
    "    cfg.model.train_cfg = None\n",
    "    model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "    fp16_cfg = cfg.get('fp16', None)\n",
    "    if fp16_cfg is not None:\n",
    "        wrap_fp16_model(model)\n",
    "    checkpoint = load_checkpoint(model, args.checkpoint, map_location='cpu')\n",
    "    if args.fuse_conv_bn:\n",
    "        model = fuse_conv_bn(model)\n",
    "    # old versions did not save class info in checkpoints, this walkaround is\n",
    "    # for backward compatibility\n",
    "    if 'CLASSES' in checkpoint.get('meta', {}):\n",
    "        model.CLASSES = checkpoint['meta']['CLASSES']\n",
    "    else:\n",
    "        model.CLASSES = dataset.CLASSES\n",
    "\n",
    "    if not distributed:\n",
    "        model = MMDataParallel(model, device_ids=[0])\n",
    "        outputs = single_gpu_test(model, data_loader, args.show, args.show_dir,\n",
    "                                  args.show_score_thr)\n",
    "    else:\n",
    "        model = MMDistributedDataParallel(\n",
    "            model.cuda(),\n",
    "            device_ids=[torch.cuda.current_device()],\n",
    "            broadcast_buffers=False)\n",
    "        outputs = multi_gpu_test(model, data_loader, args.tmpdir,\n",
    "                                 args.gpu_collect)\n",
    "\n",
    "    rank, _ = get_dist_info()\n",
    "    if rank == 0:\n",
    "        if args.out:\n",
    "            print(f'\\nwriting results to {args.out}')\n",
    "            mmcv.dump(outputs, args.out)\n",
    "        kwargs = {} if args.eval_options is None else args.eval_options\n",
    "        if args.format_only:\n",
    "            dataset.format_results(outputs, **kwargs)\n",
    "        if args.eval:\n",
    "            eval_kwargs = cfg.get('evaluation', {}).copy()\n",
    "            # hard-code way to remove EvalHook args\n",
    "            for key in [\n",
    "                    'interval', 'tmpdir', 'start', 'gpu_collect', 'save_best',\n",
    "                    'rule', 'dynamic_intervals'\n",
    "            ]:\n",
    "                eval_kwargs.pop(key, None)\n",
    "            eval_kwargs.update(dict(metric=args.eval, **kwargs))\n",
    "            metric = dataset.evaluate(outputs, **eval_kwargs)\n",
    "            print(metric)\n",
    "            metric_dict = dict(config=args.config, metric=metric)\n",
    "            if args.work_dir is not None and rank == 0:\n",
    "                mmcv.dump(metric_dict, json_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
