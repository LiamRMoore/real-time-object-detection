{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e4c8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# picodet from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c17ea0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Sequence, Optional, Union\n",
    "from pydantic.dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmcv.runner import BaseModule\n",
    "from mmdet.models.utils import make_divisible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ba37cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ESNetSize:\n",
    "    scale: float\n",
    "    channel_ratios: list[float]\n",
    "        \n",
    "Small = ESNetSize(\n",
    "    scale=0.75,\n",
    "    channel_ratios=[\n",
    "        0.875, 0.5, 0.5, 0.5, 0.625, 0.5, 0.625,\n",
    "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5\n",
    "    ]\n",
    ")\n",
    "\n",
    "Medium = ESNetSize(\n",
    "    scale=1.0,\n",
    "    channel_ratios=[\n",
    "        0.875, 0.5, 1.0, 0.625, 0.5, 0.75, 0.625, \n",
    "        0.625, 0.5, 0.625, 1.0, 0.625, 0.75\n",
    "    ]\n",
    ")\n",
    "\n",
    "Large = ESNetSize(\n",
    "    scale=1.25,\n",
    "    channel_ratios=[\n",
    "        0.875, 0.5, 1.0, 0.625, 0.5, 0.75, 0.625, \n",
    "        0.625, 0.5, 0.625, 1.0, 0.625, 0.75\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2aed1",
   "metadata": {},
   "source": [
    "## Backbone: ESNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac6e4538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.activation.Hardswish"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmcv.cnn.bricks.activation import ACTIVATION_LAYERS\n",
    "from torch.nn import Hardswish\n",
    "from mmdet.models.utils.inverted_residual import EnhancedInvertedResidualDS, EnhancedInvertedResidual  \n",
    "\n",
    "\n",
    "ACTIVATION_LAYERS.register_module(Hardswish, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d1c18c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESNet(BaseModule):\n",
    "    \"\"\"\n",
    "    Enhanced ShuffleNet used in PicoDet\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_size : \n",
    "        String \"s\", \"m\", or \"l\"\n",
    "    out_indices : \n",
    "        Output from which stages\n",
    "    frozen_stages : \n",
    "        Stages to be frozen (stop grad and set eval mode). -1 => none.\n",
    "    conv_cfg : \n",
    "        Optional config dict for convolution layer.\n",
    "    norm_cfg : \n",
    "        Dict config for norm layer\n",
    "    act_cfg : \n",
    "        Dict config for activation layer\n",
    "    norm_eval : \n",
    "        Set norm layers to eval mode (freeze BN running stats)\n",
    "    se_cfg : \n",
    "        Config dict from SE layer\n",
    "    with_cp : \n",
    "        Use (weight) checkpointing or not (save VRAM, slow down training)\n",
    "    pretrained : \n",
    "        Optional path to pretrained model weights\n",
    "    init_cfg : \n",
    "        Initialisation config dict.\n",
    "    \"\"\"\n",
    "    stage_repeats = [3, 7, 3]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_size: ESNetSize = Small,\n",
    "        frozen_stages: int = -1,\n",
    "        conv_cfg: Optional[dict] = None,\n",
    "        norm_cfg: dict = dict(type=\"BN\", requires_grad=True),\n",
    "        act_cfg: dict = dict(type=\"Hardswish\"),\n",
    "        norm_eval: bool = False,\n",
    "        se_cfg: dict = dict(\n",
    "            conv_cfg=None,\n",
    "            ratio=4,\n",
    "            act_cfg=(\n",
    "                dict(type=\"ReLU\"),\n",
    "                dict(type=\"HSigmoid\")\n",
    "            )\n",
    "        ),\n",
    "        with_cp: bool = False,\n",
    "        init_cfg: Optional[Union[str, dict, list[dict]]] = None\n",
    "    ):\n",
    "        # weight initialisation from MMCV basemodule\n",
    "        super().__init__(init_cfg)\n",
    "        # set initialisations for different layers\n",
    "        if isinstance(init_cfg, str):\n",
    "            self.init_cfg = dict(type='Pretrained', checkpoint=init_cfg)\n",
    "        elif init_cfg is None:\n",
    "            self.init_cfg = self._init_cfg_default()\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.norm_eval = norm_eval\n",
    "        self.se_cfg = se_cfg\n",
    "        self.with_cp = with_cp\n",
    "        self.model_size = model_size\n",
    "        # define layers\n",
    "        # initial (downsampling) conv\n",
    "        self.conv_initial = ConvModule(\n",
    "            in_channels=3,\n",
    "            out_channels=self.stage_out_channels[0],\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg\n",
    "        )\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.blocks = self._create_bottleneck_blocks()\n",
    "        \n",
    "    @property\n",
    "    def scale(self):\n",
    "        return self.model_size.scale\n",
    "    \n",
    "    @property\n",
    "    def channel_ratios(self):\n",
    "        return self.model_size.channel_ratios\n",
    "    \n",
    "    @property\n",
    "    def frozen_stages(self):\n",
    "        return self._frozen_stages\n",
    "    \n",
    "    @property\n",
    "    def stage_out_channels(self):\n",
    "        return [\n",
    "            24,\n",
    "            make_divisible(128 * self.scale, divisor=16),\n",
    "            make_divisible(256 * self.scale, divisor=16),\n",
    "            make_divisible(512 * self.scale, divisor=16),\n",
    "            1024\n",
    "        ]\n",
    "    \n",
    "        \n",
    "    @frozen_stages.setter\n",
    "    def frozen_stages(self, value):\n",
    "        self._validate_frozen_stages(value)\n",
    "        self._frozen_stages = value\n",
    "        \n",
    "    def _validate_out_indices(self, value):\n",
    "        if not set(value).issubset(set(range(1, 15))):\n",
    "            raise ValueError('out_indices must be a subset of range'\n",
    "                             f'[1, 15). But received {value}')\n",
    "            \n",
    "    def _validate_frozen_stages(self, value):\n",
    "        if value not in range(-1, 4):\n",
    "            raise ValueError('frozen_stages must be in range(-1, 4). '\n",
    "                             f'But received {value}')\n",
    "            \n",
    "    def _init_cfg_default(self):\n",
    "        return [\n",
    "            dict(type='Kaiming', layer='Conv2d'),\n",
    "            dict(\n",
    "                type='Constant',\n",
    "                val=1,\n",
    "                layer=['_BatchNorm', 'GroupNorm']\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "    def _create_bottleneck_blocks(self):\n",
    "        blocks = []\n",
    "        # linear index (points back to architecture's channel_ratios)\n",
    "        arch_ix = 0\n",
    "        self.out_ixs = []\n",
    "        # always 3 stages with (3, 7, 3) repeated blocks respectively\n",
    "        for stage_ix, num_repeats in enumerate(self.stage_repeats):\n",
    "            for repeat_ix in range(num_repeats):\n",
    "                channel_scale_factor = self.channel_ratios[arch_ix]\n",
    "                mid_channels = make_divisible(\n",
    "                    int(self.stage_out_channels[stage_ix + 2] * channel_scale_factor),\n",
    "                    divisor=8\n",
    "                )\n",
    "                # first block in each stage is special case: downsampling\n",
    "                if not repeat_ix:\n",
    "                    # TODO: do i need to assign this to attr?\n",
    "                    self.se_cfg[\"channels\"] = mid_channels // 2\n",
    "                    block = EnhancedInvertedResidualDS(\n",
    "                        in_channels=self.stage_out_channels[stage_ix],\n",
    "                        mid_channels=mid_channels,\n",
    "                        out_channels=self.stage_out_channels[stage_ix + 1],\n",
    "                        stride=2,\n",
    "                        se_cfg=self.se_cfg,\n",
    "                        norm_cfg=self.norm_cfg,\n",
    "                        act_cfg=self.act_cfg,\n",
    "                        with_cp=self.with_cp,\n",
    "                        init_cfg=self.init_cfg\n",
    "                    )\n",
    "                # no downsampling\n",
    "                else:\n",
    "                    self.se_cfg[\"channels\"] = mid_channels\n",
    "                    block = EnhancedInvertedResidual(\n",
    "                        in_channels=self.stage_out_channels[stage_ix + 1],\n",
    "                        mid_channels=mid_channels,\n",
    "                        out_channels=self.stage_out_channels[stage_ix + 1],\n",
    "                        stride=1,\n",
    "                        se_cfg=self.se_cfg,\n",
    "                        norm_cfg=self.norm_cfg,\n",
    "                        act_cfg=self.act_cfg,\n",
    "                        with_cp=self.with_cp,\n",
    "                        init_cfg=self.init_cfg\n",
    "                    )\n",
    "                name = str(stage_ix + 1) + \"_\" + str(repeat_ix + 1)\n",
    "                setattr(self, name, block)\n",
    "                block.name = name\n",
    "                blocks.append(block)\n",
    "                arch_ix += 1\n",
    "            # after each set of repeating blocks; output\n",
    "            self.out_ixs.append(arch_ix)\n",
    "        return blocks\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_initial(x)\n",
    "        out = self.max_pool(out)\n",
    "        outs = []\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            out = block(out)\n",
    "            # skip lines for multi-scale interception in neck\n",
    "            if i in self.out_ixs:\n",
    "                outs.append(out)\n",
    "        return outs\n",
    "    \n",
    "    def _freeze_stages(self):\n",
    "        if self.frozen_stages >= 0:\n",
    "            for param in self.conv1.parameters():\n",
    "                param.requires_grad = False\n",
    "        for i in range(1, self.frozen_stages + 1):\n",
    "            block_num = self.stage_repeats[i]\n",
    "            for num in range(block_num):\n",
    "                layer = getattr(self, f'{i + 1}_{num + 1}')\n",
    "                layer.eval()\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "    \n",
    "    def train(self, mode=True):\n",
    "        \"\"\"Convert the model into training mode while keep normalization layer\n",
    "        frozen.\"\"\"\n",
    "        super(ESNet, self).train(mode)\n",
    "        self._freeze_stages()\n",
    "        if mode and self.norm_eval:\n",
    "            for m in self.modules():\n",
    "                # trick: eval have effect on BatchNorm only\n",
    "                if isinstance(m, _BatchNorm):\n",
    "                    m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "eee5d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "esnet = ESNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "784b9952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EnhancedInvertedResidualDS(\n",
       "   (conv_dw_1): ConvModule(\n",
       "     (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "     (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (conv_linear_1): ConvModule(\n",
       "     (conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_pw_2): ConvModule(\n",
       "     (conv): Conv2d(24, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw_2): ConvModule(\n",
       "     (conv): Conv2d(84, 84, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=84, bias=False)\n",
       "     (bn): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(84, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(21, 84, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear_2): ConvModule(\n",
       "     (conv): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw_mv1): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_pw_mv1): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidual(\n",
       "   (conv_pw): ConvModule(\n",
       "     (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw): ConvModule(\n",
       "     (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "     (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear): ConvModule(\n",
       "     (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidual(\n",
       "   (conv_pw): ConvModule(\n",
       "     (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw): ConvModule(\n",
       "     (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "     (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear): ConvModule(\n",
       "     (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidualDS(\n",
       "   (conv_dw_1): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (conv_linear_1): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_pw_2): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw_2): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear_2): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw_mv1): ConvModule(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_pw_mv1): ConvModule(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidual(\n",
       "   (conv_pw): ConvModule(\n",
       "     (conv): Conv2d(96, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw): ConvModule(\n",
       "     (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
       "     (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear): ConvModule(\n",
       "     (conv): Conv2d(240, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidual(\n",
       "   (conv_pw): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear): ConvModule(\n",
       "     (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidual(\n",
       "   (conv_pw): ConvModule(\n",
       "     (conv): Conv2d(96, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw): ConvModule(\n",
       "     (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
       "     (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear): ConvModule(\n",
       "     (conv): Conv2d(240, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidual(\n",
       "   (conv_pw): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear): ConvModule(\n",
       "     (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidual(\n",
       "   (conv_pw): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear): ConvModule(\n",
       "     (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidual(\n",
       "   (conv_pw): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw): ConvModule(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear): ConvModule(\n",
       "     (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidualDS(\n",
       "   (conv_dw_1): ConvModule(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (conv_linear_1): ConvModule(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_pw_2): ConvModule(\n",
       "     (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw_2): ConvModule(\n",
       "     (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "     (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear_2): ConvModule(\n",
       "     (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw_mv1): ConvModule(\n",
       "     (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_pw_mv1): ConvModule(\n",
       "     (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidual(\n",
       "   (conv_pw): ConvModule(\n",
       "     (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw): ConvModule(\n",
       "     (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "     (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear): ConvModule(\n",
       "     (conv): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}],\n",
       " EnhancedInvertedResidual(\n",
       "   (conv_pw): ConvModule(\n",
       "     (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       "   (conv_dw): ConvModule(\n",
       "     (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "     (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (se): SELayer(\n",
       "     (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "     (conv1): ConvModule(\n",
       "       (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): ConvModule(\n",
       "       (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (activate): HSigmoid()\n",
       "     )\n",
       "   )\n",
       "   (conv_linear): ConvModule(\n",
       "     (conv): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (activate): Hardswish()\n",
       "   )\n",
       " )\n",
       " init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esnet.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e72117ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 40, 40])\n",
      "torch.Size([1, 96, 40, 40])\n",
      "torch.Size([1, 96, 40, 40])\n",
      "torch.Size([1, 192, 20, 20])\n",
      "torch.Size([1, 192, 20, 20])\n",
      "torch.Size([1, 192, 20, 20])\n",
      "torch.Size([1, 192, 20, 20])\n",
      "torch.Size([1, 192, 20, 20])\n",
      "torch.Size([1, 192, 20, 20])\n",
      "torch.Size([1, 192, 20, 20])\n",
      "torch.Size([1, 384, 10, 10])\n",
      "torch.Size([1, 384, 10, 10])\n",
      "torch.Size([1, 384, 10, 10])\n",
      "[torch.Size([1, 96, 40, 40]), torch.Size([1, 192, 20, 20]), torch.Size([1, 384, 10, 10])]\n"
     ]
    }
   ],
   "source": [
    "esnet.stage_out_channels\n",
    "test_input = torch.from_numpy(np.random.rand(1, 3, 320, 320).astype(np.float32))\n",
    "test_outputs = esnet(test_input)\n",
    "print([a.shape for a in test_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a689d744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 10, 13]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esnet.skip_ixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9da6b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Registry(name=activation layer, items={'ReLU': <class 'torch.nn.modules.activation.ReLU'>, 'LeakyReLU': <class 'torch.nn.modules.activation.LeakyReLU'>, 'PReLU': <class 'torch.nn.modules.activation.PReLU'>, 'RReLU': <class 'torch.nn.modules.activation.RReLU'>, 'ReLU6': <class 'torch.nn.modules.activation.ReLU6'>, 'ELU': <class 'torch.nn.modules.activation.ELU'>, 'Sigmoid': <class 'torch.nn.modules.activation.Sigmoid'>, 'Tanh': <class 'torch.nn.modules.activation.Tanh'>, 'Clamp': <class 'mmcv.cnn.bricks.activation.Clamp'>, 'Clip': <class 'mmcv.cnn.bricks.activation.Clamp'>, 'GELU': <class 'torch.nn.modules.activation.GELU'>, 'HSigmoid': <class 'mmcv.cnn.bricks.hsigmoid.HSigmoid'>, 'HSwish': <class 'torch.nn.modules.activation.Hardswish'>, 'Swish': <class 'mmcv.cnn.bricks.swish.Swish'>, 'Hardswish': <class 'torch.nn.modules.activation.Hardswish'>})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTIVATION_LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc21a008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Registry(name=model, items={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MMCV_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82cf6401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESNet(\n",
       "  (conv_initial): ConvModule(\n",
       "    (conv): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate): Hardswish()\n",
       "  )\n",
       "  (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (2_1): EnhancedInvertedResidualDS(\n",
       "    (conv_dw_1): ConvModule(\n",
       "      (conv): Conv2d(25, 25, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=25, bias=False)\n",
       "      (bn): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_linear_1): ConvModule(\n",
       "      (conv): Conv2d(25, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_pw_2): ConvModule(\n",
       "      (conv): Conv2d(25, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw_2): ConvModule(\n",
       "      (conv): Conv2d(84, 84, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=84, bias=False)\n",
       "      (bn): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(84, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(21, 84, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear_2): ConvModule(\n",
       "      (conv): Conv2d(84, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw_mv1): ConvModule(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_pw_mv1): ConvModule(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (2_2): EnhancedInvertedResidual(\n",
       "    (conv_pw): ConvModule(\n",
       "      (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw): ConvModule(\n",
       "      (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear): ConvModule(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (2_3): EnhancedInvertedResidual(\n",
       "    (conv_pw): ConvModule(\n",
       "      (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw): ConvModule(\n",
       "      (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear): ConvModule(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (3_1): EnhancedInvertedResidualDS(\n",
       "    (conv_dw_1): ConvModule(\n",
       "      (conv): Conv2d(97, 97, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=97, bias=False)\n",
       "      (bn): BatchNorm2d(97, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_linear_1): ConvModule(\n",
       "      (conv): Conv2d(97, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_pw_2): ConvModule(\n",
       "      (conv): Conv2d(97, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw_2): ConvModule(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear_2): ConvModule(\n",
       "      (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw_mv1): ConvModule(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_pw_mv1): ConvModule(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (3_2): EnhancedInvertedResidual(\n",
       "    (conv_pw): ConvModule(\n",
       "      (conv): Conv2d(192, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw): ConvModule(\n",
       "      (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
       "      (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear): ConvModule(\n",
       "      (conv): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (3_3): EnhancedInvertedResidual(\n",
       "    (conv_pw): ConvModule(\n",
       "      (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw): ConvModule(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear): ConvModule(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (3_4): EnhancedInvertedResidual(\n",
       "    (conv_pw): ConvModule(\n",
       "      (conv): Conv2d(192, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw): ConvModule(\n",
       "      (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
       "      (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear): ConvModule(\n",
       "      (conv): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (3_5): EnhancedInvertedResidual(\n",
       "    (conv_pw): ConvModule(\n",
       "      (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw): ConvModule(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear): ConvModule(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (3_6): EnhancedInvertedResidual(\n",
       "    (conv_pw): ConvModule(\n",
       "      (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw): ConvModule(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear): ConvModule(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (3_7): EnhancedInvertedResidual(\n",
       "    (conv_pw): ConvModule(\n",
       "      (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw): ConvModule(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear): ConvModule(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (4_1): EnhancedInvertedResidualDS(\n",
       "    (conv_dw_1): ConvModule(\n",
       "      (conv): Conv2d(193, 193, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=193, bias=False)\n",
       "      (bn): BatchNorm2d(193, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_linear_1): ConvModule(\n",
       "      (conv): Conv2d(193, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_pw_2): ConvModule(\n",
       "      (conv): Conv2d(193, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw_2): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear_2): ConvModule(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw_mv1): ConvModule(\n",
       "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_pw_mv1): ConvModule(\n",
       "      (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (4_2): EnhancedInvertedResidual(\n",
       "    (conv_pw): ConvModule(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear): ConvModule(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (4_3): EnhancedInvertedResidual(\n",
       "    (conv_pw): ConvModule(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "    (conv_dw): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (se): SELayer(\n",
       "      (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv1): ConvModule(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): ConvModule(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activate): HSigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_linear): ConvModule(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       ")\n",
       "init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c5b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_divisible()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
